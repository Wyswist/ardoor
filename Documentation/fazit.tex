\documentclass[main.tex]{subfiles}
\begin{document}

\section{Fazit}

Leider konnten wir unser Ziel, eine perspektivisch korrekte Augmented Reality Szene darzustellen nicht erreichen. Die Fehlerursache ist bis Dato unklar. Wir haben unsere Logik mehrfach mit diversen Beispielapplikationen abgeglichen und konnten was die Berechnung der Perspektive anbelangt keine Unterschiede feststellen. 
\paragraph{}
Was die Plattformunabhängigkeit und das Verständnis der Theorie anbelangt, so haben wir diese Ziele umsetzen können. Mit der ARDoor Library konnten wir den Kern der Applikation, welcher den Grossteil der Logik enthält plattformunabhängig halten und ihn auf verschiedenen mobilen wie auch Desktop Plattformen einsetzen. Bei der Theorie war es überraschend, wie schwer es ist bezüglich der in OpenCV integrierten Funktion solvePnP Informationen zu finden. Dies war eine grosse Hürde und wir können uns bis heute nicht 100\% sicher sein, ob die von uns erarbeitete Theorie mit der Implementierung in OpenCV übereinstimmt. Der Quellcode von OpenCV ist wenig aufschlüssig, da die meisten Variablen nicht aussagekräftig benannt wurden. Dadurch ist es extrem schwer, die einzelnen Prozesse nachzuvollziehen. Dies ist definitiv eine Schwäche der OpenCV-Dokumentation. Sie enthält zwar oft schon Verweise auf die Theorie hinter einigen Funktionen, jedoch ist dies nur bei den einfacheren Algorithmen der Fall, wo es auch so einfach ist Informationen dazu im Internet zu finden.
\paragraph{}
Die Arbeit am Projekt 2 hat uns eine gute Möglichkeit geboten uns bezüglich der Entwicklung auf Mobilen einen Überblick zu verschaffen und die Möglichkeiten zu ergründen. OpenCV war uns ein Nützliches Werkzeug und hat uns sehr viel Arbeit abgenommen, da die Implementation von Algorithmen wie sie hinter solvePnP stecken schon eine Semesterarbeit an sich darstellen können. Nichts desto trotz ist es erwiesen, dass wir uns für den weiteren Verlauf während der Bachelor-Thesis nicht voll und ganz auf OpenCV verlassen können. Wollen wir eine einigermassen akzeptable Framerate erreichen, so werden wir wohl auch auf Hilfsmittel wie OpenCL und NEON zurückgreifen müssen. Auch wird es eventuell auch erforderlich sein, wieder mehr plattformspezifischen Code zu schreiben, da es oft nur so möglich ist, die Ressourcen der Mobilen Geräte voll auszuschöpfen. Und auch mit allen Optimierungen wird ein flüssiges Augmented Reality Video mit 28 fps wohl kaum zu erreichen sein. Jedenfalls nicht mit den von uns eingesetzten Geräten. Aktuelle iPhone und Android Devices bieten noch einiges mehr an Leistung und könnten den Schlüssel zu einer flüssigen Wiedergabe bilden.

\end{document}
